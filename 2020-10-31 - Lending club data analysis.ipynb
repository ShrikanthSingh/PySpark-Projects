{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c87440b3-591e-4805-8f3f-a712196328d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Cleaning and Analysis using PySpark \n",
    "* Dataset - https://www.kaggle.com/wordsforthewise/lending-club\n",
    "* Steps involved:\n",
    "  - Cleaning the data in the column using regex expressions\n",
    "  - Analysing the correlation between different features\n",
    "  - Pattern understanding from inter column frequency table\n",
    "  - Handling null values\n",
    "  - Merging of columns\n",
    "  - Transforming multi label data into binary data\n",
    "  \n",
    "** Note - The notebook was practised on databricks community version and hence doesnt contain any sparksession initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6482be4c-f067-47c9-b0ac-35c938b94601",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"/FileStore/tables/LoanStats_2018Q4.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f9997bf0-97a4-43af-9e6b-593635b63668",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2a19760-300f-49de-81d7-d922d2232de9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel = df.select('term', 'home_ownership', 'grade', 'purpose', 'int_rate', 'addr_state',\n",
    "                  'loan_status', 'application_type', 'loan_amnt', 'emp_length', 'annual_inc',\n",
    "                  'dti', 'delinq_2yrs', 'revol_util', 'total_acc', 'num_tl_90g_dpd_24m','dti_joint')\n",
    "df_sel.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7ff3ee81-0a60-4690-a321-d3043f4de175",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7986f145-3261-4508-b334-f3ab7ddadb7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, regexp_extract\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fea695b6-515c-4a5d-b9a7-b049228268be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cleaning the columns emp_length, term\n",
    "df_sel = df_sel.withColumn('emp_cleaned', regexp_extract(col('emp_length'), '\\\\d+', 0)).withColumn('term_cleaned', regexp_replace(col('term'), 'months', ''))\n",
    "df_sel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e9ea98a-f6e2-4c3d-b86f-610878af9a4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a view or table\n",
    "temp_table_name = 'loan_status_intermediate'\n",
    "df_sel.createOrReplaceTempView(temp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "512add34-a19a-41dc-9fb7-12bf4b5650f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "          select * from loan_status_intermediate\n",
    "          ''').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2adc52e0-133f-428b-9345-098546c53ca5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Verify the correlation between Annual inc and loan amount\n",
    "'''\n",
    "Correlation is a normalized measure of covariance that is easier to understand, as it provides quantitative measurements of the statistical dependence between two random variables.\n",
    "'''\n",
    "df_sel.stat.corr('annual_inc', 'loan_amnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c363c060-b464-43aa-a817-1e4f622ab833",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Analysing the frequency distribution between two features i.e loan_status and grade using cross tab.\n",
    "'''\n",
    "Cross Tabulation provides a table of the frequency distribution for a set of variables.\n",
    "'''\n",
    "df_sel.stat.crosstab('loan_status', 'grade').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7bcbdf2e-40c6-4b1e-83dc-f9a47f065495",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Checking the frequent occurences in the column 'purpose' and 'grade' \n",
    "freq = df_sel.stat.freqItems(['purpose', 'grade'], 0.3)\n",
    "freq.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7275165-7f63-426f-a910-af67956e6db6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel.groupBy(df_sel.purpose).count().orderBy(desc('count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6eaaef3f-eeff-4960-98ef-98e9eb384170",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tradeoff between statiscal accurcy and time of operation. \n",
    "#The more lenient the allowable_err the more faster the execution\n",
    "quants =[0.25, 0.5, 0.75]\n",
    "allowable_err = 0.05\n",
    "df_sel.approxQuantile('loan_amnt', quants, allowable_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfb86598-a379-4af4-beb4-df7929d1e799",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Analysing null values in the columns\n",
    "df_sel.select([count(when(isnan(c)|col(c).isNull(), c)).alias(c) for c in df_sel.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f636592e-0a3a-4e27-a32e-01be3b63de0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel = df_sel.dropna(how='all', subset=['loan_status'])\n",
    "df_sel.select([count(when(isnan(c)|col(c).isNull(), c)).alias(c) for c in df_sel.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e8723210-89c5-41a8-8348-c8f72e1880f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel = df_sel.withColumn('revol_util_cleaned', regexp_extract(col('revol_util'), '\\\\d+', 0))\n",
    "df_sel.select(['revol_util','revol_util_cleaned']).show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0a077555-49c7-4659-9454-8b75a3a4aa60",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fill_avg(df, column_name):\n",
    "  return df.select(column_name).agg(avg(column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fec0af30-3091-4ae4-8ea8-b34a494be113",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rev_avg = fill_avg(df_sel, 'revol_util_cleaned').first()[0]\n",
    "df_sel = df_sel.withColumn('revol_util_avg', lit(rev_avg))\n",
    "df_sel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ce3adf75-58c4-4b15-8758-ebbb45b2077a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Replace the Null value in the revol util column with the average value\n",
    "df_sel = df_sel.withColumn('revol_util_cleaned', coalesce(col('revol_util_cleaned'), col('revol_util_avg')))\n",
    "df_sel = df_sel.withColumn('revol_util_cleaned', col('revol_util_cleaned').cast('double'))\n",
    "df_sel.describe('revol_util_cleaned').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c16bfb2a-386b-4d34-95ac-896d93e6a019",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "          select application_type, dti, dti_joint from loan_status_intermediate where dti is null\n",
    "          ''').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed7b9d1d-849b-467d-bbbf-00b4cfb28018",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#replace the null values from dti column with the values from dti_joint along that row.\n",
    "df_sel= df_sel.withColumn('dti_cleaned', coalesce(col('dti'), col('dti_joint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4efdcd96-e855-4cae-9ee3-42d42aed326a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "distinct_ids = [x.loan_status for x in df_sel.select('loan_status').distinct().collect()]\n",
    "distinct_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "33f0b1fd-e652-4139-a4fe-1000209cfeb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Converting multi label data into final by transforming different types of loan into two categories as Yes and No. Yes means bad loan and No mean good loan.\n",
    "df_sel = df_sel.withColumn('bad_loan', when(df_sel.loan_status.isin(['Fully Paid', 'Current']), 'No').otherwise('Yes'))\n",
    "df_sel.groupBy('bad_loan').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "78af5b1b-3475-4912-832f-f7330bbe411b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel.drop('dti_joint', 'revol_util', 'dti')\n",
    "df_sel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "60d5b53f-36c7-4bcc-bcd8-08e4da7e007f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sel.stat.crosstab('bad_loan', 'grade').show()\n",
    "#inference - grade A is very good loan and the goodness decreases along B, C, D....Reason - The Yes and No ratio is seen to increase from A to G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "952b355c-0090-4dd4-9cca-dedaf830e905",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "permanent_table = 'processes_loan'\n",
    "df_sel.write.format('parquet').saveAsTable(permanent_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "55e22ca9-da6a-40ac-b9e4-7e729edc0a22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "          SELECT * from processes_loan\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bd82bb99-1479-4d5c-be10-8c36df0f1d44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a view or table\n",
    "\n",
    "temp_table_name = \"LoanStats_2018Q4_csv\"\n",
    "\n",
    "df.createOrReplaceTempView(temp_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e4eabe94-77cc-416d-b5a7-3f22e0c7ccf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "2020-10-31 - Lending club data analysis",
   "notebookOrigID": 4281302127954961,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
